{"cells":[{"cell_type":"markdown","metadata":{"id":"cqWXXYRFuDEy"},"source":["# Import"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s8ELJIgkXsBG"},"outputs":[],"source":["import pandas as pd\n","import random\n","import os\n","import time\n","import numpy as np\n","from sklearn.metrics import mean_squared_error\n","from tqdm import tqdm\n","import math\n","from filterpy.kalman import KalmanFilter\n","from filterpy.common import Q_discrete_white_noise\n","import itertools\n","import math"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fuNqIm91XsDz"},"outputs":[],"source":["def seed_everything(seed):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","seed_everything(1422) # Seed 고정"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z2pp9fBhXsM-"},"outputs":[],"source":["train_df = pd.read_csv('./data/train.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NSyImCAPXsPu"},"outputs":[],"source":["train_x = train_df.filter(regex='X') # Input : X Featrue\n","train_y = train_df.filter(regex='Y') # Output : Y Feature"]},{"cell_type":"markdown","metadata":{"id":"-0tenc9HqLT6"},"source":["# Feature Engineering"]},{"cell_type":"markdown","metadata":{"id":"2HjiFs6OqLT7"},"source":["## Train data"]},{"cell_type":"markdown","metadata":{"id":"MYx4RoG3qLT9"},"source":["### Kalman Filter"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BcbRG6vogzwZ"},"outputs":[],"source":["train_x.drop([\"X_10\",\"X_11\"], axis =1 ,inplace =True)\n","\n","basic_col = train_x.columns\n","\n","for i in tqdm(range(len(train_x.columns))):\n","    current=0\n","    sum_c=[]\n","    z = train_x.loc[:, train_x.columns[i]]\n","    a = []           #필터링 된 피쳐(after)\n","    b = []           #필터링 전 피쳐(before)\n","    my_filter = KalmanFilter(dim_x=2,dim_z=1) #create kalman filter\n","    my_filter.x = np.array([[2.],[0.]])       # initial state (location and velocity)\n","    my_filter.F = np.array([[1.,1.], [0.,1.]])    # state transition matrix\n","    my_filter.H = np.array([[1.,0.]])    # Measurement function\n","    my_filter.P *= 1000.                 # covariance matrix\n","    my_filter.R = 5                      # state uncertainty\n","    my_filter.Q = Q_discrete_white_noise(dim = 2,dt=.1,var=.1) # process uncertainty   \n","    for k in z.values:\n","        my_filter.predict()\n","        my_filter.update(k)\n","        # do something with the output\n","        x = my_filter.x\n","        a.extend(x[0])\n","        b.append(k)\n","    sum_c=sum_c+a\n","    train_x.loc[:,'kf_X_'+str(i)]=sum_c\n","train_x"]},{"cell_type":"markdown","metadata":{"id":"OwkZtsh7qLUL"},"source":["### 가설 기반 Feature Engineering"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sTS9NeFBqLUM"},"outputs":[],"source":["temp_1 = ['X_14','X_15','X_16','X_17','X_18']\n","temp_2 = ['X_19','X_20','X_21','X_22']\n","temp_3 = ['X_30','X_31','X_32','X_33']\n","\n","# 0값이 있는 피쳐 제외하고 log 변환 (log1p 사용 안함)\n","for col in basic_col:\n","    if col in ['X_38','X_39',\"X_40\",\"X_45\"]:\n","        continue\n","    train_x[col+\"_log\"] = train_x[col].apply(lambda x : math.log(x))\n","\n","# 가설 1. 안테나 패드 위치 간의 차이가 공정예측에 영향을 미칠 것임\n","for a,b in itertools.combinations(temp_1,2):\n","    train_x['dif_'+a+b] = train_x[a]-train_x[b]\n","    train_x['dif_'+b+a] = train_x[b]-train_x[a]\n","    \n","# 가설 2. 스크류 삽입 깊이의 차이가 공정예측에 영향을 미칠 것임 \n","for a,b in itertools.combinations(temp_2,2):\n","    train_x['dif_'+a+b] = train_x[a]-train_x[b]\n","    train_x['dif_'+b+a] = train_x[b]-train_x[a]\n"," \n"," # 가설 3. 스크류 삽입 깊이의 차이가 공정예측에 영향을 미칠 것임 \n","for a,b in itertools.combinations(temp_3,2):\n","    train_x['dif_'+a+b] = train_x[a]-train_x[b]\n","    train_x['dif_'+b+a] = train_x[b]-train_x[a]\n","    \n","# 가설 4. PCB 체결시 단계별 누름량 1,2의 총합이 공정예측에 영향을 미칠 것임\n","train_x['PCB_sum_1'] = train_x['X_01']+train_x['X_02']\n","\n","# 가설 5. PCB 체결시 단계별 누름량 3,4의 총합이 공정예측에 영향을 미칠 것임\n","train_x['PCB_sum_2'] = train_x['X_05']+train_x['X_06']\n","\n","# 가설 6. 방열재료의 총면적이 공정예측에 영향을 미칠 것임\n","train_x['radi_sum_area'] = train_x['X_07'] + train_x['X_08']+ train_x['X_09']\n","\n","# 가설 7. 방열재료 면적당 무게가 공정예측에 영향을 미칠 것임\n","train_x['radi_1_weight_per_area'] = train_x['X_03'] / train_x['X_07']\n","\n","# 가설 8. 레이돔 치수와 안테나 위치의 거리가 공정예측에 영향을 미칠 것임\n","train_x['abs_X_41X_14'] =abs(train_x[\"X_41\"]- train_x['X_14'])\n","train_x['abs_X_42X_15'] =abs(train_x[\"X_42\"]- train_x['X_15'])\n","train_x['abs_X_43X_16'] =abs(train_x[\"X_43\"]- train_x['X_16'])\n","train_x['abs_X_44X_17'] =abs(train_x[\"X_44\"]- train_x['X_17'])\n","\n","# 가설 9. 안테나패드 위치, 스크류삽입깊이, 커넥터 핀 치수, 스크류삽입깊이의 편차(분산 또는 표준편차)가 공정예측에 영향을 미칠 것임\n","train_x['var_antena_loc'] = train_x[['X_14','X_15','X_16','X_17',\"X_18\"]].apply(lambda x : np.var(x), axis =1)\n","train_x['std_nthscrew_depth'] = train_x[['X_19','X_20','X_21','X_22']].apply(lambda x : np.std(x), axis =1)\n","train_x['std_connector'] = train_x[['X_24','X_25','X_26','X_27',\"X_28\",\"X_29\"]].apply(lambda x : np.std(x), axis =1)\n","train_x['std_screw_depth'] = train_x[['X_30','X_31','X_32','X_33']].apply(lambda x : np.std(x), axis =1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"59_9NQzWqLUV"},"outputs":[],"source":["train_x.to_csv('./data/train_x_no_mean_median.csv', index=False) # 중간 저장"]},{"cell_type":"markdown","metadata":{"id":"EPN8R3VeqLUY"},"source":["## Test data"]},{"cell_type":"markdown","metadata":{"id":"zoLFcUjfqLUZ"},"source":["### Kalman Filter"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0j2YICIHYKyc"},"outputs":[],"source":["submit_x = pd.read_csv('./data/test.csv')\n","submit_x.drop([\"ID\",\"X_10\",\"X_11\"],axis =1 ,inplace =True)\n","submit_df = pd.read_csv('./data/sample_submission.csv')\n","\n","basic_col = submit_x.columns\n","\n","for i in tqdm(range(len(submit_x.columns))):\n","    current=0\n","    sum_c=[]\n","    z = submit_x.loc[:, submit_x.columns[i]]\n","    a = []           #필터링 된 피쳐(after)\n","    b = []           #필터링 전 피쳐(before)\n","    my_filter = KalmanFilter(dim_x=2,dim_z=1) #create kalman filter\n","    my_filter.x = np.array([[2.],[0.]])       # initial state (location and velocity)\n","    my_filter.F = np.array([[1.,1.], [0.,1.]])    # state transition matrix\n","    my_filter.H = np.array([[1.,0.]])    # Measurement function\n","    my_filter.P *= 1000.                 # covariance matrix\n","    my_filter.R = 5                      # state uncertainty\n","    my_filter.Q = Q_discrete_white_noise(dim = 2,dt=.1,var=.1) # process uncertainty   \n","    for k in z.values:\n","        my_filter.predict()\n","        my_filter.update(k)\n","        # do something with the output\n","        x = my_filter.x\n","        a.extend(x[0])\n","        b.append(k)\n","    sum_c=sum_c+a\n","    submit_x.loc[:,'kf_X_'+str(i)]=sum_c"]},{"cell_type":"markdown","metadata":{"id":"0NmPhXuKqLUc"},"source":["### 가설 기반 Feature Engineering"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E-ajtXjoqLUd"},"outputs":[],"source":["\n","for col in basic_col:\n","    if col in ['X_38','X_39',\"X_40\",\"X_45\"]:\n","        continue\n","    submit_x[col+\"_log\"] = submit_x[col].apply(lambda x : math.log(x))\n","\n","\n","for a,b in itertools.combinations(temp_1,2):\n","  submit_x['dif_'+a+b] = submit_x[a]-submit_x[b]\n","  submit_x['dif_'+b+a] = submit_x[b]-submit_x[a]\n","\n","for a,b in itertools.combinations(temp_2,2):\n","  submit_x['dif_'+a+b] = submit_x[a]-submit_x[b]\n","  submit_x['dif_'+b+a] = submit_x[b]-submit_x[a]\n","\n","\n","for a,b in itertools.combinations(temp_3,2):\n","  submit_x['dif_'+a+b] = submit_x[a]-submit_x[b]\n","  submit_x['dif_'+b+a] = submit_x[b]-submit_x[a]\n","\n","submit_x['PCB_sum_1'] = submit_x['X_01']+submit_x['X_02']\n","submit_x['PCB_sum_2'] = submit_x['X_05']+submit_x['X_06']\n","submit_x['radi_sum_area'] = submit_x['X_07'] + submit_x['X_08']+ submit_x['X_09']\n","submit_x['radi_1_weight_per_area'] = submit_x['X_03'] / submit_x['X_07']\n","\n","submit_x['abs_X_41X_14'] =abs(submit_x[\"X_41\"]- submit_x['X_14'])\n","submit_x['abs_X_42X_15'] =abs(submit_x[\"X_42\"]- submit_x['X_15'])\n","submit_x['abs_X_43X_16'] =abs(submit_x[\"X_43\"]- submit_x['X_16'])\n","submit_x['abs_X_44X_17'] =abs(submit_x[\"X_44\"]- submit_x['X_17'])\n","\n","\n","submit_x['var_antena_loc'] = submit_x[['X_14','X_15','X_16','X_17',\"X_18\"]].apply(lambda x : np.var(x), axis =1)\n","submit_x['std_nthscrew_depth'] = submit_x[['X_19','X_20','X_21','X_22']].apply(lambda x : np.std(x), axis =1)\n","submit_x['std_connector'] = submit_x[['X_24','X_25','X_26','X_27',\"X_28\",\"X_29\"]].apply(lambda x : np.std(x), axis =1)\n","submit_x['std_screw_depth'] = submit_x[['X_30','X_31','X_32','X_33']].apply(lambda x : np.std(x), axis =1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fc6P1W4SqLUf"},"outputs":[],"source":["submit_x.to_csv('./data/test_x_no_mean_median.csv', index=False)"]},{"cell_type":"markdown","metadata":{"id":"vetym9JZqLUg"},"source":["# 평균, 중간값 생성"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0MgsYD-FqLUh"},"outputs":[],"source":["class CFG:\n","    seed = 42\n","    fold_num = 10\n","\n","    trainPath = './data/train_x_no_mean_median.csv'\n","    testPath = './data/test_x_no_mean_median.csv'\n","    \n","train_df = pd.read_csv(CFG.trainPath)\n","test_df = pd.read_csv(CFG.testPath)\n","\n","train_new_df = train_df.copy()\n","test_new_df = test_df.copy()\n","\n","# 이동 평균 구하는 함수\n","def make_mean_median(column_list, set_amount):\n","    mean_arr = []\n","    median_arr = []\n","    \n","    # 첫 set_amount까지는 본래값 사용\n","    for i in range(set_amount):\n","        mean_arr.append(column_list[i])\n","        median_arr.append(column_list[i])\n","    \n","    # set_amount만큼의 mean, median 생성\n","    for i in range(set_amount, len(column_list)):\n","        mean_arr.append(float(np.mean(column_list[i-set_amount:i])))\n","        median_arr.append(float(np.median(column_list[i-set_amount:i])))\n","        \n","    print(f'mean_arr:{len(mean_arr)}')\n","    print(f'median_arr:{len(median_arr)}')\n","    return mean_arr.copy(), median_arr.copy()\n","\n","# 이동 중간값 구하는 함수\n","def make_move_avg_median(df, save_file_name, type=None, set_amount=30):\n","    pbar = tqdm(df.columns[:54])\n","    for column in pbar:\n","        column_list = df[column].to_list()\n","        pbar.set_description(f\"The mean and median of {column} is making\")\n","        meanArr, medianArr = make_mean_median(column_list, set_amount)\n","        \n","        df[f'{column}_mean_{set_amount}'] = meanArr\n","        df[f'{column}_median_{set_amount}'] = medianArr\n","        \n","    df.to_csv(save_file_name, index=False)\n","\n","# 모델이 학습할 최종 데이터셋 추출\n","make_move_avg_median(train_df, save_file_name='./data/train_x_engineered.csv', type='train')\n","make_move_avg_median(test_df, save_file_name='./data/test_x_engineered.csv', type='test')"]},{"cell_type":"code","source":["mean_arr = []\n","median_arr = []\n","    \n","# 첫 set_amount까지는 본래값 사용\n","for i in range(30):\n","    mean_arr.append(column_list[i])\n","    median_arr.append(column_list[i])\n","    \n","    # set_amount만큼의 mean, median 생성\n","for i in range(30, len(column_list)):\n","    mean_arr.append(float(np.mean(column_list[i-set_amount:i])))\n","    median_arr.append(float(np.median(column_list[i-set_amount:i])))"],"metadata":{"id":"GAm2X0fYuNbg"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"provenance":[],"toc_visible":true},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.7.8 ('project2')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.8"},"vscode":{"interpreter":{"hash":"b6389e48aef19c6f81724b07620f5ff09e9361a4d0793dd16062a4e70922359a"}}},"nbformat":4,"nbformat_minor":0}